{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to eliminate all batches to the same dictionary\n",
    "\n",
    "Author - Artem Popov (arti32lehtonen)\n",
    "\n",
    "-----------------\n",
    "\n",
    "Every batch is independent of all the batches obtained from the same collection. Hence, different token_id may correspond to the same word in different batches. This notebook shows how to change it and eliminate all batches to the same dictionary. It can be useful when you often rewrite your batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eliminate_batches_to_same_dictionary(old_batches_path, new_batches_path):\n",
    "    \"\"\"\n",
    "    Eliminate all batches from one folder to the same dictionary (in alphabetical order). \n",
    "\n",
    "    Parametrs:\n",
    "    ----------\n",
    "    old_batches_path : folder containing all batches\n",
    "    \n",
    "    new_batches_path : folder that will contain all batches after function implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_words = get_words_from_batches(batches_path)\n",
    "    main_dictionary = list_to_word_index_dictionary(list_of_words)\n",
    "    \n",
    "    for batch_path in sorted(glob.glob(batches_path + \"/*.batch\")):\n",
    "        batch = artm.messages.Batch()\n",
    "        \n",
    "        with open(batch_path, \"rb\") as f:\n",
    "            batch.ParseFromString(f.read())\n",
    "        \n",
    "        new_batch = rewrite_batch_with_dictionary(batch, main_dictionary)\n",
    "        \n",
    "        batch_name = batch_path[batch_path.rfind('/'):]\n",
    "        \n",
    "        with open(new_batches_path + batch_name, 'wb') as fout:\n",
    "            fout.write(new_batch.SerializeToString())\n",
    "    \n",
    "    return 0 \n",
    "        \n",
    "         \n",
    "def get_words_from_batches(batches_path):\n",
    "    \"\"\"\n",
    "    Get set of words from the all batches and making one big dictionary for all of them\n",
    "    \"\"\"\n",
    "    set_of_words = set()\n",
    "    \n",
    "    for batch_path in sorted(glob.glob(batches_path + \"/*.batch\")):\n",
    "        batch = artm.messages.Batch()\n",
    "        \n",
    "        with open(batch_path, \"rb\") as f:\n",
    "            batch.ParseFromString(f.read())\n",
    "        \n",
    "        set_of_words = set_of_words.union(set(batch.token))\n",
    "        \n",
    "    return sorted(list(set_of_words))\n",
    "\n",
    "\n",
    "def list_to_word_index_dictionary(list_of_words):\n",
    "    \"\"\"\n",
    "    Transform list of unique elements to the dictionary of format {element:element index}\n",
    "    \"\"\"\n",
    "    return dict(zip(list_of_words, xrange(0, len(list_of_words))))\n",
    "\n",
    "\n",
    "def list_to_index_word_dictionary(list_of_words):\n",
    "    \"\"\"\n",
    "    Transform list of unique elements to the dictionary of format {element index:element}\n",
    "    \"\"\"\n",
    "\n",
    "    return dict(zip( xrange(0, len(list_of_words)), list_of_words))\n",
    "\n",
    "\n",
    "def rewrite_batch_with_dictionary(batch, main_dictionary):\n",
    "    \"\"\"\n",
    "    Create new batch with the same content as the old batch, but with \n",
    "    tokens corresponds to tokens from main_dictionary\n",
    "    \n",
    "    Parametrs:\n",
    "    ----------\n",
    "    batch : old batch\n",
    "    \n",
    "    main_dictionary: element:element index dictionary of all collection\n",
    "    \"\"\"\n",
    "    \n",
    "    new_batch = artm.messages.Batch()\n",
    "    new_batch.id = str(uuid.uuid4())\n",
    "    \n",
    "    for token in sorted(main_dictionary.keys()):\n",
    "        new_batch.token.append(token)\n",
    "        new_batch.class_id.append(u'@default_class')\n",
    "    \n",
    "    batch_dictionary = list_to_index_word_dictionary(batch.token)\n",
    "    \n",
    "    for old_item in batch.item:\n",
    "        new_item = new_batch.item.add()\n",
    "        new_item.id = old_item.id\n",
    "        new_item.title = old_item.title\n",
    "\n",
    "        for one_token_id, one_token_weight in zip(old_item.token_id, old_item.token_weight):\n",
    "            new_item.token_id.append(main_dictionary[batch_dictionary[one_token_id]])\n",
    "            new_item.token_weight.append(one_token_weight)    \n",
    "    \n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eliminate_batches_to_same_dictionary('batches/my_batches', 'batches/my_batches_new')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
