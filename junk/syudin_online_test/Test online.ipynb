{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import artm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_list = [\n",
    "    {\n",
    "        'name': 'nips',\n",
    "        'path': 'Nips/',\n",
    "        'format': 'bow_uci',\n",
    "        'batch_folder': 'Nips/batches',\n",
    "        'dictionary': 'Nips/dictionary.txt',\n",
    "    },\n",
    "    {\n",
    "        'name': 'wiki-en',\n",
    "        'path': 'Wiki-En/',\n",
    "        'format': 'vowpal_wabbit',\n",
    "        'batch_folder': 'Wiki-En/batches',\n",
    "        'dictionary': 'Wiki-En/dictionary.txt',\n",
    "    },\n",
    "    {\n",
    "        'name': 'pubmed',\n",
    "        'path': 'Pubmed/',\n",
    "        'format': 'bow_uci',\n",
    "        'batch_folder': 'Pubmed/batches',\n",
    "        'dictionary': 'Pubmed/dictionary.txt',\n",
    "    },\n",
    "    {\n",
    "        'name': 'nytimes',\n",
    "        'path': 'Nytimes/',\n",
    "        'format': 'bow_uci',\n",
    "        'batch_folder': 'Nytimes/batches',\n",
    "        'dictionary': 'Nytimes/dictionary.txt',\n",
    "    },\n",
    "    {\n",
    "        'name': 'lyrics',\n",
    "        'path': 'Lyrics/',\n",
    "        'format': 'vowpal_wabbit',\n",
    "        'batch_folder': 'Lyrics/batches',\n",
    "        'dictionary': 'Lyrics/dictionary.txt',\n",
    "    },\n",
    "    {\n",
    "        'name': 'wiki-enru',\n",
    "        'path': 'Wiki-En-Ru/',\n",
    "        'format': 'vowpal_wabbit',\n",
    "        'batch_folder': 'Wiki-En-Ru/batches',\n",
    "        'dictionary': 'Wiki-En-Ru/dictionary.txt',\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_prepare(data_dict):\n",
    "    data_format = data_dict['format']\n",
    "    if data_format == 'vowpal_wabbit':\n",
    "        data_path = data_dict['path'] + 'vw.{}.txt'.format(data_dict['name'])\n",
    "    else:\n",
    "        data_path = data_dict['path']\n",
    "    collection_name = data_dict['name']\n",
    "    target_folder = data_dict['batch_folder']\n",
    "    dictionary_path = data_dict['dictionary']\n",
    "    batch_vectorizer = artm.BatchVectorizer(\n",
    "        data_path=data_path,\n",
    "        data_format=data_format,\n",
    "        collection_name=collection_name,\n",
    "        target_folder=target_folder,\n",
    "    )\n",
    "    dictionary = artm.Dictionary()\n",
    "    dictionary.gather(data_path=target_folder)\n",
    "    dictionary.save_text(dictionary_path=dictionary_path)\n",
    "\n",
    "\n",
    "def data_offline_fit(data_dict):\n",
    "    collection_name = data_dict['name']\n",
    "    target_folder = data_dict['batch_folder']\n",
    "    dictionary_path = data_dict['dictionary']\n",
    "    \n",
    "    batch_vectorizer = artm.BatchVectorizer(\n",
    "        data_path=target_folder,\n",
    "        data_format='batches',\n",
    "    )\n",
    "    dictionary = artm.Dictionary()\n",
    "    dictionary.load_text(dictionary_path=dictionary_path)\n",
    "    \n",
    "    offline_model = artm.ARTM(\n",
    "        num_topics=20,\n",
    "        dictionary=dictionary,\n",
    "        num_processors=2,\n",
    "    )\n",
    "    offline_model.scores.add(artm.PerplexityScore(\n",
    "            name='PerplexityScore',\n",
    "            dictionary=dictionary\n",
    "    ))\n",
    "    offline_model.scores.add(artm.TopTokensScore(name='top_tokens_score'))\n",
    "    offline_model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)\n",
    "    \n",
    "    perplex_score = offline_model.score_tracker['PerplexityScore'].value\n",
    "    tokens_score = offline_model.score_tracker['top_tokens_score'].last_tokens\n",
    "    print(\"Collection - {}, Perplexity - {}\".format(\n",
    "        collection_name,\n",
    "        offline_model.score_tracker['PerplexityScore'].last_value,\n",
    "    ))\n",
    "    phi = offline_model.get_phi()\n",
    "    phi.to_csv(data_dict['path'] + 'phi.tsv', sep='\\t')\n",
    "    \n",
    "    return perplex_score, tokens_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data_dict in all_data_list:\n",
    "    data_prepare(data_dict)\n",
    "    print('{} done'.format(data_dict['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection - nips, Perplexity - 1567.3600178254426\n",
      "\n",
      "Collection - wiki-en, Perplexity - 6701.67167326759\n",
      "\n",
      "Collection - pubmed, Perplexity - 3956.646160311604\n",
      "\n",
      "Collection - nytimes, Perplexity - 5167.75077711719\n",
      "\n",
      "Collection - lyrics, Perplexity - 535.1523577440564\n",
      "\n",
      "Collection - wiki-enru, Perplexity - 6072.576865014042\n"
     ]
    }
   ],
   "source": [
    "for data_dict in all_data_list:\n",
    "    data_dict['perplex_score'], data_dict['tokens_score'] = data_offline_fit(data_dict)\n",
    "    pd.DataFrame.from_dict(data_dict, orient='index').to_csv(data_dict['path'] + 'offline_result.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Смотрим на онлайн \"из коробки\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_online_fit(data_dict):\n",
    "    collection_name = data_dict['name']\n",
    "    target_folder = data_dict['batch_folder']\n",
    "    dictionary_path = data_dict['dictionary']\n",
    "    \n",
    "    batch_vectorizer = artm.BatchVectorizer(\n",
    "        data_path=target_folder,\n",
    "        data_format='batches',\n",
    "    )\n",
    "    dictionary = artm.Dictionary()\n",
    "    dictionary.load_text(dictionary_path=dictionary_path)\n",
    "    \n",
    "    online_model = artm.ARTM(\n",
    "        num_topics=20,\n",
    "        dictionary=dictionary,\n",
    "        num_processors=2,\n",
    "    )\n",
    "    online_model.scores.add(artm.PerplexityScore(\n",
    "            name='PerplexityScore',\n",
    "            dictionary=dictionary\n",
    "    ))\n",
    "    online_model.scores.add(\n",
    "        artm.TopTokensScore(name='top_tokens_score')\n",
    "    )\n",
    "    online_model.fit_online(\n",
    "        batch_vectorizer=batch_vectorizer,\n",
    "        update_every=int(batch_vectorizer.num_batches / 20) + 1,\n",
    "    )\n",
    "    \n",
    "    fit_perplex_score = online_model.score_tracker['PerplexityScore'].value\n",
    "    tokens_score = online_model.score_tracker['top_tokens_score'].last_tokens\n",
    "    \n",
    "    online_model.scores.add(artm.PerplexityScore(\n",
    "            name='FinalPerplexity',\n",
    "            dictionary=dictionary,\n",
    "    ))\n",
    "    online_model.transform(\n",
    "        batch_vectorizer=batch_vectorizer,\n",
    "        theta_matrix_type=None\n",
    "    )\n",
    "    perplexity = online_model.get_score('FinalPerplexity').value\n",
    "\n",
    "    #phi = online_model.get_phi()\n",
    "    #phi.to_csv(data_dict['path'] + 'phi_online1.tsv', sep='\\t')\n",
    "    \n",
    "    return perplexity, fit_perplex_score, tokens_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data_list = []\n",
    "for data_dict in all_data_list:\n",
    "    data_dict = {x: str(data_dict[x]) for x in data_dict}\n",
    "    new_data_list.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nips done\n",
      "wiki-en done\n",
      "pubmed done\n",
      "nytimes done\n",
      "lyrics done\n",
      "wiki-enru done\n"
     ]
    }
   ],
   "source": [
    "for data_dict in all_data_list:\n",
    "    data_dict['perplex_score_online_final'], data_dict['perplex_score_online0'], data_dict['tokens_score_online0'] = data_online_fit(data_dict)\n",
    "    data_dict['perplex_score_online_final'], data_dict['perplex_score_online0'], data_dict['tokens_score_online0'] = str(data_dict['perplex_score_online_final']), str(data_dict['perplex_score_online0']), str(data_dict['tokens_score_online0'])\n",
    "    pd.DataFrame.from_dict(data_dict, orient='index').to_csv(data_dict['path'] + 'online_result_base.tsv', sep='\\t', header=None)\n",
    "    print data_dict['name'] + ' done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection - nips, Perplexity - 2378.67793044\n",
      "Collection - wiki-en, Perplexity - 8111.0757332\n",
      "Collection - pubmed, Perplexity - 4854.35310672\n",
      "Collection - nytimes, Perplexity - 6178.12057525\n",
      "Collection - lyrics, Perplexity - 606.563782487\n",
      "Collection - wiki-enru, Perplexity - 7426.74240867\n"
     ]
    }
   ],
   "source": [
    "for data_dict in all_data_list:\n",
    "    data_info = pd.read_csv(data_dict['path'] + 'online_result_base.tsv', sep='\\t', header=None, index_col=0)\n",
    "    data_info = data_info.to_dict()[1]\n",
    "    print(\"Collection - {}, Perplexity - {}\".format(\n",
    "        data_info['name'],\n",
    "        data_info['perplex_score_online_final'],\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
